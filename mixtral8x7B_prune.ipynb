{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B9wHxmg0XSeX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import IA3Config, get_peft_model, TaskType\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XInZ4dUtedQY"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "54a25a9849084505bf03372dcf10414b",
      "2b421ed992434f6fbea7cc2e29469218",
      "9ef3577747c344869d42d97016a5085b",
      "d797303cf6fd416999a37b46e976332e",
      "eb5dc4587e8a4185aa458281e50132f7",
      "04d154a13b794e9b868cbd4e4227723d",
      "17c831c297e941e385a73ac58597f1fe",
      "3efd8bd097e84c3db2a69bd9808508f5",
      "3c4ad8b0a51447f4b1c435dbf13de766",
      "df2b506610de46718aa3483f072a5fb6",
      "0109b52b27f640e09b26fe02fec8ba15",
      "959743a194d643aaa5132d7f01c4c7b7",
      "fbab1fca0d5949f5b99921be667e7577",
      "72cd383b98234a639ee099cd2e0c708b",
      "6a25e7d61d6c4e46bf2d033ed4ef5bbd",
      "7ac53c5fb8764ff482a3e871f8ca79c4",
      "9c88719f88cd47198753d77114e7b3b5",
      "8587716852cc4e8f930761895570e016",
      "5346e05b2927440c863e7de6d80092da",
      "88630b330257409a92560945e1354847"
     ]
    },
    "id": "aPdO2c-Ef_-M",
    "outputId": "1821cbcb-a784-4760-eff3-1616c794441b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c643cccdf2604eaf8eb94e92f589b6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== k = 1 =====\n",
      "0 : [2]\n",
      "1 : [1]\n",
      "2 : [4]\n",
      "3 : [3]\n",
      "4 : [4]\n",
      "5 : [3]\n",
      "6 : [3]\n",
      "7 : [3]\n",
      "8 : [0]\n",
      "9 : [6]\n",
      "10 : [6]\n",
      "11 : [5]\n",
      "12 : [5]\n",
      "13 : [5]\n",
      "14 : [5]\n",
      "15 : [1]\n",
      "16 : [4]\n",
      "17 : [0]\n",
      "18 : [4]\n",
      "19 : [3]\n",
      "20 : [7]\n",
      "21 : [1]\n",
      "22 : [3]\n",
      "23 : [1]\n",
      "24 : [6]\n",
      "25 : [5]\n",
      "26 : [6]\n",
      "27 : [0]\n",
      "28 : [6]\n",
      "29 : [7]\n",
      "30 : [3]\n",
      "31 : [4]\n",
      "\n",
      "===== k = 2 =====\n",
      "0 : [2, 0]\n",
      "1 : [1, 0]\n",
      "2 : [4, 6]\n",
      "3 : [3, 4]\n",
      "4 : [4, 5]\n",
      "5 : [3, 4]\n",
      "6 : [3, 4]\n",
      "7 : [3, 1]\n",
      "8 : [0, 3]\n",
      "9 : [6, 1]\n",
      "10 : [6, 7]\n",
      "11 : [5, 0]\n",
      "12 : [5, 6]\n",
      "13 : [5, 0]\n",
      "14 : [5, 0]\n",
      "15 : [1, 3]\n",
      "16 : [4, 5]\n",
      "17 : [0, 2]\n",
      "18 : [4, 3]\n",
      "19 : [3, 4]\n",
      "20 : [7, 3]\n",
      "21 : [1, 6]\n",
      "22 : [3, 1]\n",
      "23 : [1, 4]\n",
      "24 : [6, 5]\n",
      "25 : [5, 2]\n",
      "26 : [6, 4]\n",
      "27 : [0, 7]\n",
      "28 : [6, 5]\n",
      "29 : [7, 4]\n",
      "30 : [3, 1]\n",
      "31 : [4, 0]\n",
      "\n",
      "===== k = 3 =====\n",
      "0 : [2, 0, 4]\n",
      "1 : [1, 0, 6]\n",
      "2 : [4, 6, 2]\n",
      "3 : [3, 4, 2]\n",
      "4 : [4, 5, 2]\n",
      "5 : [3, 4, 6]\n",
      "6 : [3, 4, 0]\n",
      "7 : [3, 1, 2]\n",
      "8 : [0, 3, 5]\n",
      "9 : [6, 1, 0]\n",
      "10 : [6, 7, 1]\n",
      "11 : [5, 0, 6]\n",
      "12 : [5, 6, 1]\n",
      "13 : [5, 0, 4]\n",
      "14 : [5, 0, 3]\n",
      "15 : [1, 3, 5]\n",
      "16 : [4, 5, 0]\n",
      "17 : [0, 2, 7]\n",
      "18 : [4, 3, 2]\n",
      "19 : [3, 4, 2]\n",
      "20 : [7, 3, 2]\n",
      "21 : [1, 6, 5]\n",
      "22 : [3, 1, 4]\n",
      "23 : [1, 4, 5]\n",
      "24 : [6, 5, 4]\n",
      "25 : [5, 2, 4]\n",
      "26 : [6, 4, 1]\n",
      "27 : [0, 7, 1]\n",
      "28 : [6, 5, 1]\n",
      "29 : [7, 4, 0]\n",
      "30 : [3, 1, 6]\n",
      "31 : [4, 0, 6]\n",
      "\n",
      "===== k = 4 =====\n",
      "0 : [2, 0, 4, 7]\n",
      "1 : [1, 0, 6, 4]\n",
      "2 : [4, 6, 2, 0]\n",
      "3 : [3, 4, 2, 0]\n",
      "4 : [4, 5, 2, 6]\n",
      "5 : [3, 4, 6, 2]\n",
      "6 : [3, 4, 0, 6]\n",
      "7 : [3, 1, 2, 4]\n",
      "8 : [0, 3, 5, 4]\n",
      "9 : [6, 1, 0, 4]\n",
      "10 : [6, 7, 1, 3]\n",
      "11 : [5, 0, 6, 1]\n",
      "12 : [5, 6, 1, 0]\n",
      "13 : [5, 0, 4, 7]\n",
      "14 : [5, 0, 3, 7]\n",
      "15 : [1, 3, 5, 7]\n",
      "16 : [4, 5, 0, 3]\n",
      "17 : [0, 2, 7, 1]\n",
      "18 : [4, 3, 2, 1]\n",
      "19 : [3, 4, 2, 7]\n",
      "20 : [7, 3, 2, 6]\n",
      "21 : [1, 6, 5, 3]\n",
      "22 : [3, 1, 4, 7]\n",
      "23 : [1, 4, 5, 2]\n",
      "24 : [6, 5, 4, 1]\n",
      "25 : [5, 2, 4, 1]\n",
      "26 : [6, 4, 1, 5]\n",
      "27 : [0, 7, 1, 5]\n",
      "28 : [6, 5, 1, 4]\n",
      "29 : [7, 4, 0, 1]\n",
      "30 : [3, 1, 6, 0]\n",
      "31 : [4, 0, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"\n",
    "Layer 0:\n",
    "  smallest 1: expert IDs = [2]\n",
    "  smallest 2: expert IDs = [2, 0]\n",
    "  smallest 3: expert IDs = [2, 0, 4]\n",
    "  smallest 4: expert IDs = [2, 0, 4, 7]\n",
    "Layer 1:\n",
    "  smallest 1: expert IDs = [1]\n",
    "  smallest 2: expert IDs = [1, 0]\n",
    "  smallest 3: expert IDs = [1, 0, 6]\n",
    "  smallest 4: expert IDs = [1, 0, 6, 4]\n",
    "Layer 2:\n",
    "  smallest 1: expert IDs = [4]\n",
    "  smallest 2: expert IDs = [4, 6]\n",
    "  smallest 3: expert IDs = [4, 6, 2]\n",
    "  smallest 4: expert IDs = [4, 6, 2, 0]\n",
    "Layer 3:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 4]\n",
    "  smallest 3: expert IDs = [3, 4, 2]\n",
    "  smallest 4: expert IDs = [3, 4, 2, 0]\n",
    "Layer 4:\n",
    "  smallest 1: expert IDs = [4]\n",
    "  smallest 2: expert IDs = [4, 5]\n",
    "  smallest 3: expert IDs = [4, 5, 2]\n",
    "  smallest 4: expert IDs = [4, 5, 2, 6]\n",
    "Layer 5:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 4]\n",
    "  smallest 3: expert IDs = [3, 4, 6]\n",
    "  smallest 4: expert IDs = [3, 4, 6, 2]\n",
    "Layer 6:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 4]\n",
    "  smallest 3: expert IDs = [3, 4, 0]\n",
    "  smallest 4: expert IDs = [3, 4, 0, 6]\n",
    "Layer 7:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 1]\n",
    "  smallest 3: expert IDs = [3, 1, 2]\n",
    "  smallest 4: expert IDs = [3, 1, 2, 4]\n",
    "Layer 8:\n",
    "  smallest 1: expert IDs = [0]\n",
    "  smallest 2: expert IDs = [0, 3]\n",
    "  smallest 3: expert IDs = [0, 3, 5]\n",
    "  smallest 4: expert IDs = [0, 3, 5, 4]\n",
    "Layer 9:\n",
    "  smallest 1: expert IDs = [6]\n",
    "  smallest 2: expert IDs = [6, 1]\n",
    "  smallest 3: expert IDs = [6, 1, 0]\n",
    "  smallest 4: expert IDs = [6, 1, 0, 4]\n",
    "Layer 10:\n",
    "  smallest 1: expert IDs = [6]\n",
    "  smallest 2: expert IDs = [6, 7]\n",
    "  smallest 3: expert IDs = [6, 7, 1]\n",
    "  smallest 4: expert IDs = [6, 7, 1, 3]\n",
    "Layer 11:\n",
    "  smallest 1: expert IDs = [5]\n",
    "  smallest 2: expert IDs = [5, 0]\n",
    "  smallest 3: expert IDs = [5, 0, 6]\n",
    "  smallest 4: expert IDs = [5, 0, 6, 1]\n",
    "Layer 12:\n",
    "  smallest 1: expert IDs = [5]\n",
    "  smallest 2: expert IDs = [5, 6]\n",
    "  smallest 3: expert IDs = [5, 6, 1]\n",
    "  smallest 4: expert IDs = [5, 6, 1, 0]\n",
    "Layer 13:\n",
    "  smallest 1: expert IDs = [5]\n",
    "  smallest 2: expert IDs = [5, 0]\n",
    "  smallest 3: expert IDs = [5, 0, 4]\n",
    "  smallest 4: expert IDs = [5, 0, 4, 7]\n",
    "Layer 14:\n",
    "  smallest 1: expert IDs = [5]\n",
    "  smallest 2: expert IDs = [5, 0]\n",
    "  smallest 3: expert IDs = [5, 0, 3]\n",
    "  smallest 4: expert IDs = [5, 0, 3, 7]\n",
    "Layer 15:\n",
    "  smallest 1: expert IDs = [1]\n",
    "  smallest 2: expert IDs = [1, 3]\n",
    "  smallest 3: expert IDs = [1, 3, 5]\n",
    "  smallest 4: expert IDs = [1, 3, 5, 7]\n",
    "Layer 16:\n",
    "  smallest 1: expert IDs = [4]\n",
    "  smallest 2: expert IDs = [4, 5]\n",
    "  smallest 3: expert IDs = [4, 5, 0]\n",
    "  smallest 4: expert IDs = [4, 5, 0, 3]\n",
    "Layer 17:\n",
    "  smallest 1: expert IDs = [0]\n",
    "  smallest 2: expert IDs = [0, 2]\n",
    "  smallest 3: expert IDs = [0, 2, 7]\n",
    "  smallest 4: expert IDs = [0, 2, 7, 1]\n",
    "Layer 18:\n",
    "  smallest 1: expert IDs = [4]\n",
    "  smallest 2: expert IDs = [4, 3]\n",
    "  smallest 3: expert IDs = [4, 3, 2]\n",
    "  smallest 4: expert IDs = [4, 3, 2, 1]\n",
    "Layer 19:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 4]\n",
    "  smallest 3: expert IDs = [3, 4, 2]\n",
    "  smallest 4: expert IDs = [3, 4, 2, 7]\n",
    "Layer 20:\n",
    "  smallest 1: expert IDs = [7]\n",
    "  smallest 2: expert IDs = [7, 3]\n",
    "  smallest 3: expert IDs = [7, 3, 2]\n",
    "  smallest 4: expert IDs = [7, 3, 2, 6]\n",
    "Layer 21:\n",
    "  smallest 1: expert IDs = [1]\n",
    "  smallest 2: expert IDs = [1, 6]\n",
    "  smallest 3: expert IDs = [1, 6, 5]\n",
    "  smallest 4: expert IDs = [1, 6, 5, 3]\n",
    "Layer 22:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 1]\n",
    "  smallest 3: expert IDs = [3, 1, 4]\n",
    "  smallest 4: expert IDs = [3, 1, 4, 7]\n",
    "Layer 23:\n",
    "  smallest 1: expert IDs = [1]\n",
    "  smallest 2: expert IDs = [1, 4]\n",
    "  smallest 3: expert IDs = [1, 4, 5]\n",
    "  smallest 4: expert IDs = [1, 4, 5, 2]\n",
    "Layer 24:\n",
    "  smallest 1: expert IDs = [6]\n",
    "  smallest 2: expert IDs = [6, 5]\n",
    "  smallest 3: expert IDs = [6, 5, 4]\n",
    "  smallest 4: expert IDs = [6, 5, 4, 1]\n",
    "Layer 25:\n",
    "  smallest 1: expert IDs = [5]\n",
    "  smallest 2: expert IDs = [5, 2]\n",
    "  smallest 3: expert IDs = [5, 2, 4]\n",
    "  smallest 4: expert IDs = [5, 2, 4, 1]\n",
    "Layer 26:\n",
    "  smallest 1: expert IDs = [6]\n",
    "  smallest 2: expert IDs = [6, 4]\n",
    "  smallest 3: expert IDs = [6, 4, 1]\n",
    "  smallest 4: expert IDs = [6, 4, 1, 5]\n",
    "Layer 27:\n",
    "  smallest 1: expert IDs = [0]\n",
    "  smallest 2: expert IDs = [0, 7]\n",
    "  smallest 3: expert IDs = [0, 7, 1]\n",
    "  smallest 4: expert IDs = [0, 7, 1, 5]\n",
    "Layer 28:\n",
    "  smallest 1: expert IDs = [6]\n",
    "  smallest 2: expert IDs = [6, 5]\n",
    "  smallest 3: expert IDs = [6, 5, 1]\n",
    "  smallest 4: expert IDs = [6, 5, 1, 4]\n",
    "Layer 29:\n",
    "  smallest 1: expert IDs = [7]\n",
    "  smallest 2: expert IDs = [7, 4]\n",
    "  smallest 3: expert IDs = [7, 4, 0]\n",
    "  smallest 4: expert IDs = [7, 4, 0, 1]\n",
    "Layer 30:\n",
    "  smallest 1: expert IDs = [3]\n",
    "  smallest 2: expert IDs = [3, 1]\n",
    "  smallest 3: expert IDs = [3, 1, 6]\n",
    "  smallest 4: expert IDs = [3, 1, 6, 0]\n",
    "Layer 31:\n",
    "  smallest 1: expert IDs = [4]\n",
    "  smallest 2: expert IDs = [4, 0]\n",
    "  smallest 3: expert IDs = [4, 0, 6]\n",
    "  smallest 4: expert IDs = [4, 0, 6, 3]\n",
    "\"\"\"\n",
    "\n",
    "k_dicts = {1: {}, 2: {}, 3: {}, 4: {}}\n",
    "\n",
    "current_layer = None\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    line = line.strip()\n",
    "    \n",
    "    m_layer = re.match(r\"Layer\\s+(\\d+):\", line)\n",
    "    if m_layer:\n",
    "        current_layer = int(m_layer.group(1))\n",
    "        continue\n",
    "    \n",
    "    m_k = re.match(r\"smallest\\s+(\\d+):\\s+expert IDs\\s*=\\s*\\[([0-7,\\s]*)\\]\", line)\n",
    "    if m_k:\n",
    "        k = int(m_k.group(1))\n",
    "        ids = m_k.group(2)\n",
    "        ids = ids.strip()\n",
    "        if ids == \"\":\n",
    "            parsed = []\n",
    "        else:\n",
    "            parsed = [int(x) for x in ids.split(\",\")]\n",
    "        k_dicts[k][current_layer] = parsed\n",
    "\n",
    "for k in range(1, 5):\n",
    "    print(f\"\\n===== k = {k} =====\")\n",
    "    for layer in range(32):\n",
    "        print(layer, \":\", k_dicts[k][layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import MixtralForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU and cache settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty the cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_disk_space(path, required_gb=100):\n",
    "\t\"\"\"Check if there's enough disk space available.\"\"\"\n",
    "\tstats = shutil.disk_usage(path)\n",
    "\tavailable_gb = stats.free / (2**30)  # Convert to GB\n",
    "\treturn available_gb >= required_gb, available_gb\n",
    "\n",
    "class PrunedMixtralSparseMoeBlock(nn.Module):\n",
    "\tdef __init__(self, original_moe, pruned_experts):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.pruned_experts = sorted(pruned_experts)\n",
    "\t\t\n",
    "\t\t# Prune the gate network\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toriginal_weight = original_moe.gate.weight\n",
    "\t\t\tmask = torch.ones(original_weight.size(0), dtype=torch.bool)\n",
    "\t\t\tmask[pruned_experts] = False\n",
    "\t\t\tnew_weight = original_weight[mask]\n",
    "\n",
    "\t\tself.gate = nn.Linear(original_moe.gate.in_features, original_moe.gate.out_features - len(pruned_experts), bias=False)\n",
    "\t\tself.gate = self.gate.to(original_weight.device)\n",
    "\t\tself.gate.weight.data = new_weight\n",
    "\t\t\n",
    "\t\t# Actually remove the pruned experts\n",
    "\t\tself.experts = nn.ModuleList([expert for i, expert in enumerate(original_moe.experts) if i not in pruned_experts])\n",
    "\t\tself.num_experts = len(self.experts)\n",
    "\n",
    "\tdef forward(self, hidden_states):\n",
    "\t\tgate_logits = self.gate(hidden_states)\n",
    "\t\tweights, selected_experts = torch.topk(gate_logits, k=2, dim=-1)\n",
    "\t\tweights = nn.functional.softmax(weights, dim=-1)\n",
    "\t\t\n",
    "\t\thidden_states = hidden_states.unsqueeze(1)  # Add sequence length dimension\n",
    "\t\texpert_outputs = torch.zeros_like(hidden_states)\n",
    "\t\tfor i, expert in enumerate(self.experts):\n",
    "\t\t\texpert_mask = (selected_experts == i).any(dim=-1).unsqueeze(-1)\n",
    "\t\t\texpert_inputs = hidden_states * expert_mask\n",
    "\t\t\texpert_outputs += expert(expert_inputs) * expert_mask\n",
    "\t\t\n",
    "\t\thidden_states = hidden_states.squeeze(1)  # Remove sequence length dimension\n",
    "\t\texpert_outputs = expert_outputs.squeeze(1)\n",
    "\t\t\n",
    "\t\toutput = torch.einsum(\"...e,...ec->...c\", weights, expert_outputs)\n",
    "\t\treturn output\n",
    "\n",
    "def prune_mixtral_experts(model, pruned_experts_per_layer):\n",
    "\tfor layer_idx, pruned_experts in pruned_experts_per_layer.items():\n",
    "\t\toriginal_moe = model.model.layers[layer_idx].block_sparse_moe\n",
    "\t\tpruned_moe = PrunedMixtralSparseMoeBlock(original_moe, pruned_experts)\n",
    "\t\tmodel.model.layers[layer_idx].block_sparse_moe = pruned_moe\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check disk space in the HF cache directory\n",
    "# cache_dir = \"/root/.cache/huggingface\"\n",
    "cache_dir = \"/root/.cache/huggingface/\"\n",
    "has_space, available_gb = check_disk_space(cache_dir)\n",
    "\n",
    "if not has_space:\n",
    "    print(f\"Warning: Only {available_gb:.2f}GB available in {cache_dir}\")\n",
    "    response = input(\"Continue anyway? (y/n): \")\n",
    "    if response.lower() != 'y':\n",
    "        print(\"Aborting operation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd99ebdca6ec43c986cbd277feaecf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde575bb1c8c40489a83d99245c8e555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe13f38738c543159ef670220695c24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe397ca11634d2db2b0060e92519b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0514d972309e4a2680f5808cf0f05df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cd325d5af441fc8c7f87433afd7bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "model = MixtralForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    torch_dtype=torch.float16,  # Use half precision\n",
    "    device_map=\"auto\"  # Automatically handle multi-GPU\n",
    "    # device_map=None,\n",
    "    # low_cpu_mem_usage=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------prune 1 experts---------------------\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ac46c4b425478babc7040b2fee1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [2], 1: [1], 2: [4], 3: [3], 4: [4], 5: [3], 6: [3], 7: [3], 8: [0], 9: [6], 10: [6], 11: [5], 12: [5], 13: [5], 14: [5], 15: [1], 16: [4], 17: [0], 18: [4], 19: [3], 20: [7], 21: [1], 22: [3], 23: [1], 24: [6], 25: [5], 26: [6], 27: [0], 28: [6], 29: [7], 30: [3], 31: [4]}\n",
      "Pruning the model...\n",
      "Model pruned!\n",
      "MixtralForCausalLM(\n",
      "  (model): MixtralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MixtralDecoderLayer(\n",
      "        (self_attn): MixtralAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (block_sparse_moe): PrunedMixtralSparseMoeBlock(\n",
      "          (gate): Linear(in_features=4096, out_features=7, bias=False)\n",
      "          (experts): ModuleList(\n",
      "            (0-6): 7 x MixtralBlockSparseTop2MLP(\n",
      "              (w1): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "              (w2): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "              (w3): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): MixtralRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): MixtralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): MixtralRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): MixtralRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n",
      "Saving model to temporary directory: temp_model_save_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/MoE_pruning/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3970: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1093ce5fc7454b7db61b1c7d1262585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Save in chunks first\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaving model to temporary directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mpruned_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemp_save_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2GB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m tokenizer.save_pretrained(temp_save_dir)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPushing to Hugging Face Hub...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/MoE_pruning/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4173\u001b[39m, in \u001b[36mPreTrainedModel.save_pretrained\u001b[39m\u001b[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[39m\n\u001b[32m   4168\u001b[39m     gc.collect()\n\u001b[32m   4170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[32m   4171\u001b[39m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[32m   4172\u001b[39m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4173\u001b[39m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4175\u001b[39m     save_function(shard, os.path.join(save_directory, shard_file))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/MoE_pruning/venv/lib/python3.12/site-packages/safetensors/torch.py:307\u001b[39m, in \u001b[36msave_file\u001b[39m\u001b[34m(tensors, filename, metadata)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_file\u001b[39m(\n\u001b[32m    277\u001b[39m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor],\n\u001b[32m    278\u001b[39m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    279\u001b[39m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    280\u001b[39m ):\n\u001b[32m    281\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[32m    283\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata=metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/MoE_pruning/venv/lib/python3.12/site-packages/safetensors/torch.py:547\u001b[39m, in \u001b[36m_flatten\u001b[39m\u001b[34m(tensors)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[33m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    540\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    541\u001b[39m     )\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    544\u001b[39m     k: {\n\u001b[32m    545\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v.dtype).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m],\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m: v.shape,\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43m_tobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    548\u001b[39m     }\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors.items()\n\u001b[32m    550\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/MoE_pruning/venv/lib/python3.12/site-packages/safetensors/torch.py:464\u001b[39m, in \u001b[36m_tobytes\u001b[39m\u001b[34m(tensor, name)\u001b[39m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    457\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are trying to save a non contiguous tensor: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` which is not allowed. It either means you\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m are trying to save tensors which are reference of each other in which case it\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms recommended to save\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m only the full tensors, and reslice at load time, or simply call `.contiguous()` on your tensor to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m pack it before saving.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m     )\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensor.device.type != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    463\u001b[39m     \u001b[38;5;66;03m# Moving tensor to cpu before saving\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     tensor = \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mctypes\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "for k in [1]:\n",
    "    print(f\"----------------------prune {k} experts---------------------\")\n",
    "    temp_save_dir = Path(f\"./temp_model_save_{k}\")\n",
    "    temp_save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(\"Loading model...\")\n",
    "    model = MixtralForCausalLM.from_pretrained(\n",
    "        \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        torch_dtype=torch.float16,  # Use half precision\n",
    "        # device_map=\"auto\"  # Automatically handle multi-GPU\n",
    "        device_map=None,\n",
    "        low_cpu_mem_usage=False\n",
    "    )\n",
    "    \n",
    "    pruned_experts_per_layer = k_dicts[k]\n",
    "    print(pruned_experts_per_layer)\n",
    "\n",
    "    print(\"Pruning the model...\")\n",
    "    pruned_model = prune_mixtral_experts(model, pruned_experts_per_layer)\n",
    "    print(\"Model pruned!\")\n",
    "\n",
    "    for n, p in pruned_model.named_parameters():\n",
    "    if getattr(p, \"is_meta\", False):\n",
    "        print(\"META FOUND!!!!!!!!!!!!:\", n)\n",
    "    print(pruned_model)\n",
    "    \n",
    "    # Save in chunks first\n",
    "    print(f\"Saving model to temporary directory: {temp_save_dir}\")\n",
    "    pruned_model.save_pretrained(\n",
    "        temp_save_dir,\n",
    "        max_shard_size=\"2GB\",\n",
    "        safe_serialization=True\n",
    "    )\n",
    "    tokenizer.save_pretrained(temp_save_dir)\n",
    "\n",
    "    print(\"Pushing to Hugging Face Hub...\")\n",
    "    pruned_model.push_to_hub(\n",
    "        repo_id=f\"kaaiiii/Mixtral_prune_{k}_experts\",\n",
    "        max_shard_size=\"2GB\",\n",
    "        safe_serialization=True\n",
    "    )\n",
    "    tokenizer.push_to_hub(\n",
    "        f\"kaaiiii/Mixtral_prune_{k}_experts\",\n",
    "    )\n",
    "    print(\"Successfully pushed to Hub!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0109b52b27f640e09b26fe02fec8ba15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04d154a13b794e9b868cbd4e4227723d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ac53c5fb8764ff482a3e871f8ca79c4",
      "placeholder": "​",
      "style": "IPY_MODEL_9c88719f88cd47198753d77114e7b3b5",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "05d9a760af1c41ad89ec5845bbbe37e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dd56b20471a40908ae5192faea7c52e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05d9a760af1c41ad89ec5845bbbe37e7",
      "placeholder": "​",
      "style": "IPY_MODEL_d7b2a17ba62848fa883004fc644bcf8e",
      "value": "Tokenizing train dataset: 100%"
     }
    },
    "17c831c297e941e385a73ac58597f1fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "2468e37498c542a6acec8e2da6394aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b421ed992434f6fbea7cc2e29469218": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3efd8bd097e84c3db2a69bd9808508f5",
      "placeholder": "​",
      "style": "IPY_MODEL_3c4ad8b0a51447f4b1c435dbf13de766",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "2e93396681fd4bbdbe4fe2c2fdf61830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ecb587af0734bb5bd7a315be2276995": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c4ad8b0a51447f4b1c435dbf13de766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3efd8bd097e84c3db2a69bd9808508f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5346e05b2927440c863e7de6d80092da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54a25a9849084505bf03372dcf10414b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_17c831c297e941e385a73ac58597f1fe"
     }
    },
    "6a25e7d61d6c4e46bf2d033ed4ef5bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "70bfb2ec31c247ebaa92b3374e950104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ecb587af0734bb5bd7a315be2276995",
      "placeholder": "​",
      "style": "IPY_MODEL_c5b5e06428bd41bd8af3cba3e74123a0",
      "value": " 7667416/7667416 [2:49:42&lt;00:00, 1534.11 examples/s]"
     }
    },
    "72cd383b98234a639ee099cd2e0c708b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ac53c5fb8764ff482a3e871f8ca79c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8587716852cc4e8f930761895570e016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5346e05b2927440c863e7de6d80092da",
      "placeholder": "​",
      "style": "IPY_MODEL_88630b330257409a92560945e1354847",
      "value": "Connecting..."
     }
    },
    "880fc8284b0147f5bce5d4f32643d32c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9b0f610edb041ce8f1ad9a678eaa23d",
      "placeholder": "​",
      "style": "IPY_MODEL_e032382be393431ca43df3399e01ff54",
      "value": "Packing train dataset: 100%"
     }
    },
    "88630b330257409a92560945e1354847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a9ad3bf4fe941ad8709322b60ce927e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c7318c173b8413783195b17221c9c55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "921b2ee5783d4eac81bdb588f3db984b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a9ad3bf4fe941ad8709322b60ce927e",
      "placeholder": "​",
      "style": "IPY_MODEL_dde16ac608a743b18fd01e12bbf917fc",
      "value": " 7667416/7667416 [02:39&lt;00:00, 23128.56 examples/s]"
     }
    },
    "959743a194d643aaa5132d7f01c4c7b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9923c2df637d4d82970719e316df0ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c88719f88cd47198753d77114e7b3b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ef3577747c344869d42d97016a5085b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_df2b506610de46718aa3483f072a5fb6",
      "placeholder": "​",
      "style": "IPY_MODEL_0109b52b27f640e09b26fe02fec8ba15",
      "value": ""
     }
    },
    "a9b0f610edb041ce8f1ad9a678eaa23d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af3ddbe36bda435db4c1679ceed298e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_880fc8284b0147f5bce5d4f32643d32c",
       "IPY_MODEL_cda47cfde59048e2be27220be040a1ff",
       "IPY_MODEL_921b2ee5783d4eac81bdb588f3db984b"
      ],
      "layout": "IPY_MODEL_e753e54a412b4c16abcf3b6782559f60"
     }
    },
    "b152aa37fb7a46a8bf75d9d6dfa019dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c7318c173b8413783195b17221c9c55",
      "max": 7667416,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2468e37498c542a6acec8e2da6394aa3",
      "value": 7667416
     }
    },
    "b64146c1aea4490cb897aea3e41a7012": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dd56b20471a40908ae5192faea7c52e",
       "IPY_MODEL_b152aa37fb7a46a8bf75d9d6dfa019dd",
       "IPY_MODEL_70bfb2ec31c247ebaa92b3374e950104"
      ],
      "layout": "IPY_MODEL_9923c2df637d4d82970719e316df0ee0"
     }
    },
    "c5b5e06428bd41bd8af3cba3e74123a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cda47cfde59048e2be27220be040a1ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e165ed5080eb45d1b4b73f28e6ddcbed",
      "max": 7667416,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e93396681fd4bbdbe4fe2c2fdf61830",
      "value": 7667416
     }
    },
    "d797303cf6fd416999a37b46e976332e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_959743a194d643aaa5132d7f01c4c7b7",
      "style": "IPY_MODEL_fbab1fca0d5949f5b99921be667e7577",
      "value": true
     }
    },
    "d7b2a17ba62848fa883004fc644bcf8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dde16ac608a743b18fd01e12bbf917fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df2b506610de46718aa3483f072a5fb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e032382be393431ca43df3399e01ff54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e165ed5080eb45d1b4b73f28e6ddcbed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e753e54a412b4c16abcf3b6782559f60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb5dc4587e8a4185aa458281e50132f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_72cd383b98234a639ee099cd2e0c708b",
      "style": "IPY_MODEL_6a25e7d61d6c4e46bf2d033ed4ef5bbd",
      "tooltip": ""
     }
    },
    "fbab1fca0d5949f5b99921be667e7577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

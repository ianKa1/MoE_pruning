{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3682c672-7d26-4e9b-8891-e9d8e6faf6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/MoE_pruning/venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:1566: UserWarning: Current model requires 800.0 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1bfb5b8af44d01877eec7e137b5634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm a 20 year old girl from the Netherlands. I'm a student in the field\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model_name = \"Qwen/Qwen1.5-MoE-A2.7B\"\n",
    "\n",
    "# 4-bit QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                 # QLoRA = 4-bit base model\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",         # QLoRA uses nf4\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "inputs = tokenizer(\"Hello!\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4adaeaf-2835-4e10-a0d8-897129ecd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2MoeForCausalLM(\n",
      "  (model): Qwen2MoeModel(\n",
      "    (embed_tokens): Embedding(151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2MoeDecoderLayer(\n",
      "        (self_attn): Qwen2MoeSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MoeSparseMoeBlock(\n",
      "          (gate): Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "          (experts): ModuleList(\n",
      "            (0-59): 60 x Qwen2MoeMLP(\n",
      "              (gate_proj): Linear4bit(in_features=2048, out_features=1408, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=2048, out_features=1408, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=1408, out_features=2048, bias=False)\n",
      "              (act_fn): SiLUActivation()\n",
      "            )\n",
      "          )\n",
      "          (shared_expert): Qwen2MoeMLP(\n",
      "            (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
      "            (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
      "            (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
      "            (act_fn): SiLUActivation()\n",
      "          )\n",
      "          (shared_expert_gate): Linear4bit(in_features=2048, out_features=1, bias=False)\n",
      "        )\n",
      "        (input_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2MoeRMSNorm((2048,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2MoeRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c6c92f-c9b9-471a-95c3-ea11db9c499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absmax': tensor([ 51, 198,  52,  ...,  59, 205, 192], dtype=torch.uint8), 'shape': torch.Size([60, 2048]), 'code': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
      "         0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000]), 'dtype': torch.float16, 'blocksize': 64, 'quant_type': 'nf4', 'offset': tensor(0.1111), 'state2': <bitsandbytes.functional.QuantState object at 0x7329c81a58b0>, 'nested': True}\n"
     ]
    }
   ],
   "source": [
    "def find_all_router_layers(model):\n",
    "    router_layers = []\n",
    "    modules = []\n",
    "    for name, module in model.named_modules():\n",
    "        if \"mlp.gate\" in name or \"mlp.shared_expert_gate\" in name or \"mpl.gate.base_layer\" in name:\n",
    "            router_layers.append(name)\n",
    "            modules.append(module)\n",
    "    return router_layers, modules\n",
    "\n",
    "routers, modules = find_all_router_layers(model)\n",
    "for i in range(1):\n",
    "    # print(routers[i], modules[i].__dict__)\n",
    "    print(modules[i].quant_state.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced0d3ed-035e-4b85-918d-af833141f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: model.layers.0.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.1.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.2.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.3.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.4.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.5.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.6.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.7.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.8.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.9.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.10.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.11.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.12.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.13.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.14.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.15.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.16.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.17.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.18.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.19.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.20.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.21.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.22.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "name: model.layers.23.mlp.gate module: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
      "weights torch.Size([61440, 1])\n",
      "weight after dequantization torch.Size([60, 2048])\n",
      " norms torch.Size([60])\n",
      "model.layers.0.mlp.gate tensor([1.3540, 1.3230, 1.4201, 1.4811, 1.3593, 1.1525, 1.2624, 1.3772, 1.3043,\n",
      "        1.3918, 1.3411, 1.3539, 1.4330, 1.3245, 1.3852, 1.3924, 1.3212, 1.4102,\n",
      "        1.4152, 1.5079, 1.3704, 1.3905, 1.3661, 1.4402, 1.2973, 1.4321, 1.4183,\n",
      "        1.3521, 1.5474, 1.3902, 1.3402, 1.3015, 1.4002, 1.1302, 1.4260, 1.3643,\n",
      "        1.5563, 1.1154, 1.3624, 1.5357, 1.3113, 1.4802, 1.6326, 1.6560, 1.2904,\n",
      "        1.1181, 1.5184, 1.3301, 1.2887, 1.4259, 1.3652, 1.3294, 1.3038, 1.4148,\n",
      "        1.3453, 1.4043, 1.4069, 1.3620, 1.5510, 1.7042])\n",
      "model.layers.1.mlp.gate tensor([1.0655, 1.0938, 1.1388, 1.0661, 1.1123, 1.2106, 1.1497, 1.1458, 1.0863,\n",
      "        1.1021, 1.0843, 1.1539, 1.1720, 1.0805, 1.2123, 1.1794, 1.1672, 1.1243,\n",
      "        1.1157, 1.1916, 1.2009, 1.0433, 1.2312, 1.0542, 1.1145, 1.2062, 1.3932,\n",
      "        1.1575, 1.2675, 1.1787, 1.1922, 1.2518, 1.2450, 1.1883, 1.2200, 1.2277,\n",
      "        1.1580, 1.1362, 1.1948, 1.1473, 1.0713, 1.1863, 1.0758, 1.1432, 1.1453,\n",
      "        1.2405, 1.1289, 1.2211, 1.1039, 1.0287, 1.0816, 1.1094, 1.1882, 1.1720,\n",
      "        1.3108, 1.1580, 1.0585, 1.1712, 1.1743, 1.0975])\n",
      "model.layers.2.mlp.gate tensor([0.9735, 1.0673, 1.0593, 1.0222, 1.0433, 1.1128, 1.0655, 1.0437, 1.0792,\n",
      "        0.9992, 1.1592, 1.1723, 0.9910, 1.1014, 1.0094, 1.0256, 1.0184, 1.0620,\n",
      "        0.9800, 1.0244, 1.0935, 1.0096, 1.1272, 0.9750, 1.0962, 1.0299, 1.0792,\n",
      "        0.9952, 1.0718, 1.0778, 1.1608, 1.0546, 1.1061, 1.0411, 1.0710, 1.0663,\n",
      "        1.0695, 1.1253, 1.0517, 1.0328, 1.0403, 1.0920, 1.0114, 1.1365, 1.0356,\n",
      "        1.0854, 1.0525, 0.9670, 1.0702, 1.0843, 1.0734, 1.0323, 0.9092, 1.0105,\n",
      "        0.9696, 1.0998, 1.0680, 0.9507, 1.1085, 0.9275])\n",
      "model.layers.3.mlp.gate tensor([1.0421, 1.1327, 0.9307, 1.0488, 1.0006, 1.1648, 1.2210, 1.0802, 1.0792,\n",
      "        0.9607, 1.0631, 1.0334, 1.0819, 1.0808, 1.0441, 1.0182, 1.1904, 1.0646,\n",
      "        1.0414, 0.9472, 1.1037, 1.0675, 1.0256, 1.0386, 1.0266, 1.0536, 0.9441,\n",
      "        1.0735, 1.1162, 1.0705, 1.0221, 1.0891, 1.0294, 1.4050, 1.0867, 0.9897,\n",
      "        1.0915, 1.1375, 1.1228, 1.0077, 1.0418, 1.0162, 1.0549, 1.0739, 1.1298,\n",
      "        1.0268, 1.0987, 0.9786, 1.1209, 1.0557, 1.1380, 0.9974, 1.0457, 1.0938,\n",
      "        1.0819, 1.0554, 1.0541, 1.0733, 1.1327, 1.0386])\n",
      "model.layers.4.mlp.gate tensor([1.0123, 1.0022, 0.9273, 1.0333, 1.0204, 1.0020, 1.1272, 1.0298, 0.9831,\n",
      "        0.9922, 1.0253, 1.1234, 1.0295, 1.0505, 1.0414, 1.0360, 1.1879, 0.8669,\n",
      "        1.0453, 1.0153, 1.0092, 1.0340, 1.0744, 0.9923, 1.1156, 1.0794, 0.9626,\n",
      "        0.9304, 1.0345, 0.9952, 1.0316, 0.9621, 0.9577, 0.9404, 0.9710, 0.9302,\n",
      "        0.9657, 0.9986, 0.9648, 1.0345, 1.0876, 0.9115, 1.0185, 1.0229, 0.9352,\n",
      "        0.8997, 1.0682, 1.0094, 1.0259, 0.9958, 1.0214, 0.9894, 0.9756, 0.9955,\n",
      "        1.0341, 1.0299, 1.1094, 0.9709, 1.0420, 1.0362])\n",
      "model.layers.5.mlp.gate tensor([0.9299, 1.0007, 0.9366, 0.9472, 0.8915, 0.9591, 0.9550, 0.9542, 1.0728,\n",
      "        0.9463, 0.9211, 1.0074, 1.0325, 0.9220, 0.9959, 0.9790, 0.9196, 0.9942,\n",
      "        1.0010, 0.9317, 0.9752, 1.0836, 1.1340, 1.0323, 0.8404, 1.0652, 1.0218,\n",
      "        1.0318, 0.9838, 1.0048, 0.9062, 0.9572, 0.8735, 1.0424, 1.0081, 0.9377,\n",
      "        0.9491, 0.9471, 0.8842, 1.0121, 0.9460, 1.0849, 1.0306, 0.9831, 1.0107,\n",
      "        0.9707, 1.0099, 0.9799, 0.9156, 0.9916, 0.9999, 1.0835, 0.9913, 0.9258,\n",
      "        0.9711, 0.9138, 0.9123, 0.9661, 0.9411, 0.8925])\n",
      "model.layers.6.mlp.gate tensor([0.7522, 0.8592, 0.8845, 0.8556, 0.8469, 0.8590, 0.7890, 0.8586, 0.8943,\n",
      "        0.8368, 0.8773, 0.7987, 0.8227, 0.9039, 0.8553, 0.8048, 0.8720, 0.8401,\n",
      "        0.8968, 0.9011, 0.8270, 0.7965, 0.9208, 0.8815, 0.8233, 0.8503, 0.8890,\n",
      "        0.8734, 0.8861, 0.8421, 0.8389, 0.8329, 0.8109, 0.9233, 0.8840, 0.9107,\n",
      "        0.8652, 0.7486, 0.9055, 0.8778, 0.8655, 0.7993, 0.8968, 0.9203, 0.8416,\n",
      "        0.9735, 0.8748, 0.8714, 0.8757, 0.8942, 0.8173, 0.8961, 0.9928, 0.8904,\n",
      "        0.8857, 0.9070, 0.8906, 0.8155, 0.9249, 0.8288])\n",
      "model.layers.7.mlp.gate tensor([0.9206, 0.9366, 0.8472, 0.8618, 0.9385, 0.8966, 0.9037, 0.9350, 0.8230,\n",
      "        0.9108, 0.7930, 0.8775, 0.8315, 0.9157, 0.9565, 0.9101, 0.8755, 0.9109,\n",
      "        0.8902, 0.9390, 0.9388, 0.8176, 0.8964, 0.9394, 0.8748, 0.8255, 0.9091,\n",
      "        0.8967, 0.9505, 0.9018, 1.0312, 0.9125, 0.8551, 0.8491, 0.9447, 0.9468,\n",
      "        0.9554, 0.8096, 0.9563, 0.8838, 0.9421, 0.8949, 0.9026, 0.8339, 0.9175,\n",
      "        0.8569, 0.8814, 0.9133, 0.9178, 0.8599, 0.9128, 0.8845, 0.9242, 0.9150,\n",
      "        0.8421, 0.8319, 0.9351, 0.8983, 0.9074, 0.8418])\n",
      "model.layers.8.mlp.gate tensor([0.8775, 0.9062, 0.8976, 0.8658, 0.9104, 0.8463, 0.7678, 0.8624, 0.8571,\n",
      "        0.8893, 0.8040, 0.8735, 0.8528, 0.8648, 0.8812, 0.8865, 0.9659, 0.8919,\n",
      "        0.9181, 0.9133, 0.8389, 0.7956, 0.9211, 0.8307, 0.8772, 0.9638, 0.8703,\n",
      "        0.9251, 0.8770, 0.9150, 0.8791, 0.8183, 0.8302, 0.9358, 0.9226, 0.8217,\n",
      "        0.9005, 0.8731, 0.8782, 0.8553, 0.8860, 0.9605, 0.8323, 0.8488, 0.8772,\n",
      "        0.9168, 1.0256, 0.8513, 0.9132, 0.9137, 0.9274, 0.8817, 0.9073, 0.8563,\n",
      "        0.9298, 0.8482, 0.8761, 0.9059, 0.8883, 0.9149])\n",
      "model.layers.9.mlp.gate tensor([0.8723, 0.8710, 0.9099, 0.8743, 0.8978, 0.8393, 0.9464, 0.8748, 0.8606,\n",
      "        0.9334, 0.9312, 0.9059, 0.9421, 0.9213, 0.9925, 0.9161, 0.8678, 0.9192,\n",
      "        0.8553, 0.8906, 0.8729, 0.9725, 0.8590, 0.8428, 0.9166, 0.8996, 0.8869,\n",
      "        0.9211, 0.9251, 0.9053, 0.8815, 0.7942, 0.8347, 0.9069, 0.9353, 0.8907,\n",
      "        0.9024, 0.8787, 0.9609, 0.9013, 1.0440, 1.0319, 0.8996, 0.8925, 0.9335,\n",
      "        0.9180, 0.8490, 0.9273, 0.8993, 0.9195, 0.9083, 0.8786, 0.9364, 0.8930,\n",
      "        0.8912, 0.9169, 0.8617, 0.9567, 0.9121, 0.8976])\n",
      "model.layers.10.mlp.gate tensor([0.8943, 0.9068, 0.9008, 0.9236, 0.8531, 0.8932, 0.8894, 0.8441, 0.9639,\n",
      "        0.9090, 0.9502, 0.9191, 0.8694, 0.8819, 0.8989, 0.8911, 0.9004, 0.8569,\n",
      "        0.8915, 0.8379, 0.9161, 0.8354, 0.8188, 0.8477, 0.8903, 0.7823, 0.8791,\n",
      "        0.8788, 0.8857, 0.8867, 0.8146, 0.8604, 0.8690, 0.8746, 0.8325, 0.9190,\n",
      "        0.8951, 0.9070, 0.8398, 0.8927, 0.9410, 0.8038, 0.8756, 0.8183, 0.8679,\n",
      "        0.9606, 0.9335, 0.8423, 0.8608, 0.8606, 0.8471, 0.8432, 0.8457, 0.8952,\n",
      "        0.9167, 0.8272, 0.7902, 0.8131, 0.8232, 0.8453])\n",
      "model.layers.11.mlp.gate tensor([0.8186, 0.8220, 0.8290, 0.7887, 0.8457, 0.8687, 0.8298, 0.8060, 0.8396,\n",
      "        0.8237, 0.8280, 0.8209, 0.8227, 0.7448, 0.9094, 0.8286, 0.8237, 0.7854,\n",
      "        0.8197, 0.8633, 0.8238, 0.8373, 0.8182, 0.8383, 0.8344, 0.7949, 0.8240,\n",
      "        0.9185, 0.8124, 0.8690, 0.8310, 0.8236, 0.8637, 0.8397, 0.8747, 0.7708,\n",
      "        0.8775, 0.8328, 0.8319, 0.8248, 0.8406, 0.7758, 0.8073, 0.7764, 0.8573,\n",
      "        0.8122, 0.8119, 0.8461, 0.8718, 0.8117, 0.8139, 0.8981, 0.8755, 0.7975,\n",
      "        0.8128, 0.8346, 0.8396, 0.8266, 0.8539, 0.8755])\n",
      "model.layers.12.mlp.gate tensor([0.8502, 0.8120, 0.9012, 0.8385, 0.7763, 0.7921, 0.8589, 0.7583, 0.7941,\n",
      "        0.7746, 0.7711, 0.7840, 0.8759, 0.7944, 0.8537, 0.7922, 0.7814, 0.8239,\n",
      "        0.8041, 0.8118, 0.7877, 0.7828, 0.7930, 0.8368, 0.8307, 0.7589, 0.8293,\n",
      "        0.7797, 0.8179, 0.7557, 0.7716, 0.8184, 0.7934, 0.8096, 0.7836, 0.7878,\n",
      "        0.7469, 0.7625, 0.7990, 0.7970, 0.7900, 0.8386, 0.7880, 0.8204, 0.8776,\n",
      "        0.7850, 0.8602, 0.7886, 0.7209, 0.7994, 0.8531, 0.8302, 0.7796, 0.8193,\n",
      "        0.8406, 0.7926, 0.8400, 0.8127, 0.7386, 0.7607])\n",
      "model.layers.13.mlp.gate tensor([0.7673, 0.7631, 0.8422, 0.7378, 0.7815, 0.7881, 0.7684, 0.7782, 0.7522,\n",
      "        0.7569, 0.7623, 0.7712, 0.8371, 0.8001, 0.7901, 0.7880, 0.7746, 0.8147,\n",
      "        0.7486, 0.7990, 0.7688, 0.7468, 0.7321, 0.8043, 0.7496, 0.7521, 0.7768,\n",
      "        0.7596, 0.7873, 0.7663, 0.7844, 0.7213, 0.7697, 0.7959, 0.7527, 0.7716,\n",
      "        0.7419, 0.7771, 0.7676, 0.7470, 0.7039, 0.7994, 0.7850, 0.8154, 0.8010,\n",
      "        0.7457, 0.7931, 0.7689, 0.7570, 0.7716, 0.8366, 0.8133, 0.7880, 0.8523,\n",
      "        0.7986, 0.7346, 0.8008, 0.7998, 0.7157, 0.7888])\n",
      "model.layers.14.mlp.gate tensor([0.7269, 0.6876, 0.6931, 0.7246, 0.7338, 0.7379, 0.7526, 0.7450, 0.6757,\n",
      "        0.6851, 0.7274, 0.7094, 0.7065, 0.7964, 0.7421, 0.6760, 0.7399, 0.7428,\n",
      "        0.7384, 0.7336, 0.7058, 0.6937, 0.7551, 0.7799, 0.7179, 0.7205, 0.7203,\n",
      "        0.7964, 0.7547, 0.7020, 0.7389, 0.7506, 0.7023, 0.7020, 0.7352, 0.7364,\n",
      "        0.7444, 0.7548, 0.7306, 0.7373, 0.7645, 0.7175, 0.7272, 0.7535, 0.7844,\n",
      "        0.7150, 0.7009, 0.6767, 0.8284, 0.7223, 0.6523, 0.6986, 0.7242, 0.7284,\n",
      "        0.7637, 0.7238, 0.7422, 0.7760, 0.8029, 0.7610])\n",
      "model.layers.15.mlp.gate tensor([0.7638, 0.7368, 0.7591, 0.7212, 0.7504, 0.7108, 0.7108, 0.7575, 0.7373,\n",
      "        0.6747, 0.6999, 0.6594, 0.7631, 0.6416, 0.7243, 0.7440, 0.7513, 0.6405,\n",
      "        0.7593, 0.7329, 0.6747, 0.7910, 0.6835, 0.7436, 0.7609, 0.6871, 0.7450,\n",
      "        0.6952, 0.7212, 0.7183, 0.7043, 0.7216, 0.6824, 0.7706, 0.7292, 0.7110,\n",
      "        0.7196, 0.7254, 0.7379, 0.7737, 0.7739, 0.6991, 0.7209, 0.6942, 0.6629,\n",
      "        0.6783, 0.7292, 0.6920, 0.6680, 0.6953, 0.6757, 0.7019, 0.7470, 0.7757,\n",
      "        0.7358, 0.7455, 0.6740, 0.7338, 0.7439, 0.7108])\n",
      "model.layers.16.mlp.gate tensor([0.6887, 0.6747, 0.6851, 0.7117, 0.6519, 0.6418, 0.7036, 0.6920, 0.6877,\n",
      "        0.7469, 0.6713, 0.6926, 0.7605, 0.7100, 0.7272, 0.7587, 0.7051, 0.7373,\n",
      "        0.7399, 0.7069, 0.6702, 0.6982, 0.7348, 0.6453, 0.7594, 0.6859, 0.6891,\n",
      "        0.7319, 0.6564, 0.7191, 0.6793, 0.7360, 0.7530, 0.7287, 0.7113, 0.7273,\n",
      "        0.7326, 0.8207, 0.7099, 0.7037, 0.6892, 0.7263, 0.6915, 0.7212, 0.7789,\n",
      "        0.7242, 0.7088, 0.7471, 0.7028, 0.6390, 0.7124, 0.7188, 0.7463, 0.6950,\n",
      "        0.7266, 0.7342, 0.6434, 0.6921, 0.6564, 0.5786])\n",
      "model.layers.17.mlp.gate tensor([0.6965, 0.7059, 0.7195, 0.7043, 0.6768, 0.6274, 0.6387, 0.6886, 0.6599,\n",
      "        0.6385, 0.7293, 0.6660, 0.6969, 0.6662, 0.5992, 0.6697, 0.6264, 0.7013,\n",
      "        0.7167, 0.6402, 0.7585, 0.7272, 0.7028, 0.6619, 0.7068, 0.6786, 0.7412,\n",
      "        0.7133, 0.6953, 0.7325, 0.7027, 0.6891, 0.6416, 0.7133, 0.7345, 0.6863,\n",
      "        0.7187, 0.7346, 0.7011, 0.6693, 0.6739, 0.7002, 0.7046, 0.7129, 0.6844,\n",
      "        0.6705, 0.7515, 0.7093, 0.7284, 0.7072, 0.7048, 0.7455, 0.7162, 0.6941,\n",
      "        0.7562, 0.6829, 0.7335, 0.6575, 0.7161, 0.6177])\n",
      "model.layers.18.mlp.gate tensor([0.7444, 0.7788, 0.7444, 0.7260, 0.7122, 0.7035, 0.7141, 0.7585, 0.6664,\n",
      "        0.7594, 0.6663, 0.7875, 0.7511, 0.7205, 0.6518, 0.7283, 0.7877, 0.7319,\n",
      "        0.6974, 0.6845, 0.7112, 0.6648, 0.7283, 0.7285, 0.7403, 0.7106, 0.7659,\n",
      "        0.7104, 0.7120, 0.7355, 0.6881, 0.7163, 0.6685, 0.7960, 0.6722, 0.7350,\n",
      "        0.7972, 0.7093, 0.7184, 0.7612, 0.7437, 0.6979, 0.6509, 0.7377, 0.7480,\n",
      "        0.7511, 0.8011, 0.7076, 0.6834, 0.7509, 0.6920, 0.7432, 0.7463, 0.7719,\n",
      "        0.7360, 0.7194, 0.7162, 0.7155, 0.7505, 0.7760])\n",
      "model.layers.19.mlp.gate tensor([0.6919, 0.6515, 0.6484, 0.7507, 0.6807, 0.6749, 0.5994, 0.6338, 0.5930,\n",
      "        0.6104, 0.6806, 0.5450, 0.6061, 0.6862, 0.7001, 0.5881, 0.6885, 0.6987,\n",
      "        0.6530, 0.7055, 0.5939, 0.7014, 0.7013, 0.6047, 0.6048, 0.6735, 0.5612,\n",
      "        0.6589, 0.6330, 0.6450, 0.6202, 0.6223, 0.6976, 0.5935, 0.6850, 0.6438,\n",
      "        0.6440, 0.6285, 0.6570, 0.6714, 0.7318, 0.6833, 0.6638, 0.6232, 0.6967,\n",
      "        0.6650, 0.6257, 0.6604, 0.6401, 0.6426, 0.7227, 0.7196, 0.7181, 0.6917,\n",
      "        0.6452, 0.6349, 0.6593, 0.7000, 0.6553, 0.6445])\n",
      "model.layers.20.mlp.gate tensor([0.6921, 0.5234, 0.6225, 0.6045, 0.6536, 0.6193, 0.5990, 0.6266, 0.6359,\n",
      "        0.6764, 0.6347, 0.6370, 0.6392, 0.6388, 0.5954, 0.6369, 0.5998, 0.6083,\n",
      "        0.6160, 0.6786, 0.6427, 0.6681, 0.6496, 0.6141, 0.6614, 0.5844, 0.6092,\n",
      "        0.6080, 0.6248, 0.6684, 0.6269, 0.6226, 0.5926, 0.6520, 0.6179, 0.6136,\n",
      "        0.6872, 0.6963, 0.6581, 0.6418, 0.6575, 0.6545, 0.7172, 0.5876, 0.6168,\n",
      "        0.5818, 0.6099, 0.5474, 0.6602, 0.6603, 0.5865, 0.5895, 0.6497, 0.6320,\n",
      "        0.6318, 0.7412, 0.6151, 0.6558, 0.6270, 0.6045])\n",
      "model.layers.21.mlp.gate tensor([0.6185, 0.5904, 0.5629, 0.6162, 0.5823, 0.6468, 0.5476, 0.6531, 0.6094,\n",
      "        0.5641, 0.5985, 0.5912, 0.5476, 0.6241, 0.5923, 0.5800, 0.6670, 0.6317,\n",
      "        0.6407, 0.5823, 0.5415, 0.5719, 0.6439, 0.6173, 0.5930, 0.6137, 0.6580,\n",
      "        0.6481, 0.5920, 0.6252, 0.5772, 0.6287, 0.6705, 0.5658, 0.6121, 0.6036,\n",
      "        0.6234, 0.6612, 0.5783, 0.6193, 0.6070, 0.5752, 0.5816, 0.5950, 0.6030,\n",
      "        0.5548, 0.5936, 0.5574, 0.5729, 0.6258, 0.6485, 0.6156, 0.6286, 0.6065,\n",
      "        0.6418, 0.6497, 0.5994, 0.7115, 0.6292, 0.5655])\n",
      "model.layers.22.mlp.gate tensor([0.6028, 0.5248, 0.5424, 0.5868, 0.5976, 0.5828, 0.5410, 0.5186, 0.5258,\n",
      "        0.6112, 0.6235, 0.5665, 0.5770, 0.5616, 0.6066, 0.5705, 0.5673, 0.5694,\n",
      "        0.5176, 0.5320, 0.5747, 0.5648, 0.6194, 0.5962, 0.5785, 0.5755, 0.5605,\n",
      "        0.4888, 0.5914, 0.5710, 0.6257, 0.5893, 0.6018, 0.5613, 0.5873, 0.6111,\n",
      "        0.5769, 0.5842, 0.4738, 0.5596, 0.5328, 0.6525, 0.5880, 0.5516, 0.6075,\n",
      "        0.6159, 0.6431, 0.5386, 0.4633, 0.6168, 0.5338, 0.5557, 0.6354, 0.4750,\n",
      "        0.5572, 0.5256, 0.5247, 0.6146, 0.5190, 0.5323])\n",
      "model.layers.23.mlp.gate tensor([0.5213, 0.6018, 0.5694, 0.5271, 0.5761, 0.4810, 0.4843, 0.6332, 0.4827,\n",
      "        0.5879, 0.5012, 0.5741, 0.6080, 0.5809, 0.5897, 0.6338, 0.5845, 0.6211,\n",
      "        0.4365, 0.6228, 0.5928, 0.4865, 0.5721, 0.5312, 0.5962, 0.6006, 0.5540,\n",
      "        0.6443, 0.4698, 0.5897, 0.5854, 0.5450, 0.5783, 0.5793, 0.6346, 0.5627,\n",
      "        0.5230, 0.5396, 0.5339, 0.4398, 0.4998, 0.6488, 0.5386, 0.6047, 0.5663,\n",
      "        0.5716, 0.5977, 0.4923, 0.5797, 0.5005, 0.6044, 0.5343, 0.6102, 0.5591,\n",
      "        0.6216, 0.5821, 0.5936, 0.5356, 0.4744, 0.5473])\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def get_gate_weight_4bit(gate):\n",
    "    # gate: Linear4bit(in_features=2048, out_features=60, bias=False)\n",
    "    \n",
    "    # 1. 量化后的 packed 权重 (Params4bit -> uint8 tensor)\n",
    "    # 有些版本是 gate.weight.data，有些要先拿 .value / .data\n",
    "    qweight = gate.weight.data    # shape: (61440, 1) or (61440,)\n",
    "    qweight = qweight.view(-1)    # 展平成 1D，方便函数吃进去\n",
    "\n",
    "    # 2. 用 quant_state 解量化\n",
    "    W = bnb.functional.dequantize_4bit(\n",
    "        qweight,\n",
    "        quant_state=gate.quant_state,   # 你刚才打印的那个 QuantState\n",
    "        quant_type=\"nf4\",               # 可写可不写，有 quant_state 时一般会被忽略\n",
    "    )\n",
    "    # 3. reshape 回原始矩阵形状：(out_features, in_features) = (60, 2048)\n",
    "    W = W.view(gate.out_features, gate.in_features)\n",
    "    return W  # float16/float32 matrix, shape == (60, 2048)\n",
    "\n",
    "\n",
    "def get_router_l2_norms(model):\n",
    "    layer_norms = {}\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if \"mlp.gate\" in name:\n",
    "            print(f\"name: {name} module: {module}\")\n",
    "            weight = module.weight  # (60, 2048)\n",
    "            print(f\"weights {weight.shape}\")\n",
    "            weight_dequantization = get_gate_weight_4bit(module)\n",
    "            print(f\"weight after dequantization {weight_dequantization.shape}\")\n",
    "            norms = torch.norm(weight_dequantization.float(), dim=1)  # shape (60,)\n",
    "            print(f\" norms {norms.shape}\")\n",
    "            layer_norms[name] = norms.detach().cpu()\n",
    "\n",
    "    return layer_norms\n",
    "\n",
    "router_norms = get_router_l2_norms(model)\n",
    "\n",
    "for name, norms in list(router_norms.items()):\n",
    "    print(name, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b1d02-8361-4dab-bc14-e5a3d95f9828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
